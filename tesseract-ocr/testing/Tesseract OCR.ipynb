{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "\n",
    "# Test character boxing\n",
    "img = cv2.imread('../cropped text/text1.jpg')\n",
    "h, w, c = img.shape\n",
    "boxes = pytesseract.image_to_boxes(img) \n",
    "for b in boxes.splitlines():\n",
    "    b = b.split(' ')\n",
    "    img = cv2.rectangle(img, (int(b[1]), h - int(b[2])), (int(b[3]), h - int(b[4])), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['level', 'page_num', 'block_num', 'par_num', 'line_num', 'word_num', 'left', 'top', 'width', 'height', 'conf', 'text'])\n"
     ]
    }
   ],
   "source": [
    "from pytesseract import Output\n",
    "\n",
    "# Test word boxing\n",
    "img = cv2.imread('../cropped text/text1.jpg')\n",
    "d = pytesseract.image_to_data(img, output_type=Output.DICT)\n",
    "print(d.keys())\n",
    "n_boxes = len(d['text'])\n",
    "for i in range(n_boxes):\n",
    "    if int(d['conf'][i]) > 60:\n",
    "        (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
    "        img = cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get grayscale image\n",
    "def get_grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# noise removal\n",
    "def remove_noise(image,amount=5):\n",
    "    return cv2.medianBlur(image,amount)\n",
    " \n",
    "#thresholding\n",
    "def thresholding(image):\n",
    "    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "#dilation\n",
    "def dilate(image):\n",
    "    kernel = np.ones((2,8),np.uint8)\n",
    "    return cv2.dilate(image, kernel, iterations = 3)\n",
    "    \n",
    "#erosion\n",
    "def erode(image,mode='V'):\n",
    "    if mode == 'V':\n",
    "        kernel = np.ones((2,1),np.uint8)\n",
    "    elif mode == 'S':\n",
    "        kernel = np.ones((3,3),np.uint8)\n",
    "        kernel[0][0] = 0\n",
    "        kernel[0][-1] = 0\n",
    "        kernel[-1][0] = 0\n",
    "        kernel[-1][-1] = 0\n",
    "    return cv2.erode(image, kernel, iterations = 1)\n",
    "\n",
    "#opening - erosion followed by dilation\n",
    "def opening(image):\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "#canny edge detection\n",
    "def canny(image):\n",
    "    return cv2.Canny(image, 100, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(image, name='img'):\n",
    "    cv2.imshow(name, image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morph(image, mode='close'):\n",
    "    if mode == 'close':\n",
    "        threshold_img = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (4,5))\n",
    "        return cv2.morphologyEx(threshold_img, cv2.MORPH_CLOSE, kernel)\n",
    "    elif mode == 'open':\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (20,1))\n",
    "        return cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base: \f",
      "\n",
      "Remove noise: \f",
      "\n",
      "Greyscale: \f",
      "\n",
      "Threshold: \f",
      "\n",
      "Opening: \f",
      "\n",
      "Canny: er\n",
      "\n",
      " \n",
      "\n",
      "QUO.0\n",
      "\n",
      "Peele are\n",
      "\f",
      "\n",
      "Morph: Rattling of doors & windows.\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test preprocessing technqiues\n",
    "\n",
    "image_base = cv2.imread('../cropped text/text3 pre-edit.jpg')\n",
    "\n",
    "image = remove_noise(image_base)\n",
    "\n",
    "show_img(image,'base')\n",
    "\n",
    "gray = get_grayscale(image)\n",
    "show_img(gray,'gray')\n",
    "\n",
    "thresh = thresholding(gray)\n",
    "show_img(thresh,'thresh')\n",
    "\n",
    "opening_img = opening(gray)\n",
    "show_img(opening_img,'opening')\n",
    " \n",
    "canny_img = canny(gray)\n",
    "show_img(canny_img,'canny')\n",
    "\n",
    "#kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (4,5))\n",
    "#morph_img = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "morph_img = morph(gray)\n",
    "show_img(morph_img,'morph')\n",
    "\n",
    "\n",
    "print(\"Base:\",pytesseract.image_to_string(image_base))\n",
    "print(\"Remove noise:\",pytesseract.image_to_string(image))\n",
    "print(\"Greyscale:\",pytesseract.image_to_string(gray))\n",
    "print(\"Threshold:\",pytesseract.image_to_string(thresh))\n",
    "print(\"Opening:\",pytesseract.image_to_string(opening_img))\n",
    "print(\"Canny:\",pytesseract.image_to_string(canny_img))\n",
    "print(\"Morph:\",pytesseract.image_to_string(morph_img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_replace_lines(img,show=False):\n",
    "    # Find edges with hough transform\n",
    "    gs_img = get_grayscale(img)\n",
    "    morph_img = dilate(gs_img)\n",
    "    edges = cv2.Canny(morph_img,255/3,255,apertureSize = 3)\n",
    "    if show:\n",
    "        show_img(edges,'edges')\n",
    "    lines = cv2.HoughLinesP(edges,0.1,np.pi/180,70,minLineLength=80,maxLineGap=3)\n",
    "    \n",
    "    # If lines are detected\n",
    "    if lines is not None:\n",
    "        # Make copies of image for later use\n",
    "        height, width, channels = img.shape\n",
    "        line_base = np.zeros((height,width,channels),np.uint8)\n",
    "        img_cpy = img.copy()\n",
    "        img_mask = img.copy()\n",
    "        \n",
    "        # Add lines to separate image\n",
    "        for line in lines:\n",
    "            x1,y1,x2,y2 = line[0]\n",
    "            x1,y1,x2,y2 = x1,y1,x2,y2\n",
    "            slope = (y2 - y1) / (x2 - x1)\n",
    "            scale = 2\n",
    "            x1new = int(x1 - scale)\n",
    "            x2new = int(x2 + scale)\n",
    "            y1new = int(y1 - scale*slope)\n",
    "            y2new = int(y2 + scale*slope)\n",
    "            cv2.line(line_base,(x1new,y1new),(x2new,y2new),(255,255,255),10)\n",
    "            cv2.line(img_cpy,(x1new,y1new),(x2new,y2new),(0,225,0),10)\n",
    "        if show:\n",
    "            show_img(img_cpy,'lines')\n",
    "        \n",
    "        # Create mask for the line image based on location of text in the original\n",
    "        # Erode and dilate image to mostly isolate text\n",
    "        img_mask = cv2.bitwise_not(img_mask)\n",
    "        kernel = np.ones((15,1),np.uint8)\n",
    "        img_mask = cv2.erode(img_mask, kernel, iterations = 1)\n",
    "        \n",
    "        # Reshape kernel for dilation\n",
    "        kernel = kernel.reshape(-1)\n",
    "        i = int(len(kernel)/2)\n",
    "        while i > 0:\n",
    "            kernel[i] = 0\n",
    "            i -= 1\n",
    "        kernel = kernel.reshape(-1,1)\n",
    "        \n",
    "        img_mask = cv2.dilate(img_mask, kernel, iterations = 1)\n",
    "        if show:\n",
    "            show_img(img_mask,'img_mask')\n",
    "            show_img(line_base,'line_base')\n",
    "            \n",
    "        # Calculate line mask by subtracting the image mask from the line base\n",
    "        line_mask = cv2.bitwise_and(img_mask, line_base)\n",
    "        line_mask = cv2.bitwise_not(line_mask)\n",
    "        masked_lines = cv2.bitwise_and(line_mask, line_base)\n",
    "\n",
    "        # Remove lines from the original image using the line mask\n",
    "        img = cv2.bitwise_or(img, masked_lines)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        ret,img = cv2.threshold(img,20,255,cv2.THRESH_BINARY)\n",
    "        if show:\n",
    "            show_img(masked_lines,'masked_lines')\n",
    "            show_img(img,'final')\n",
    "    # If no lines detected\n",
    "    else:\n",
    "        pass\n",
    "        #print(\"no lines\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sudoku.png', 'text1.jpg', 'text10.JPG', 'text11.JPG', 'text12.JPG', 'text13.JPG', 'text14.JPG', 'text15.JPG', 'text16.JPG', 'text17.jpg', 'text18.JPG', 'text19.JPG', 'text2.jpg', 'text20.JPG', 'text21.JPG', 'text22.JPG', 'text23.JPG', 'text24.JPG', 'text25.JPG', 'text26.JPG', 'text27.JPG', 'text28.JPG', 'text29.JPG', 'text3 pre-edit.jpg', 'text3.jpg', 'text30.JPG', 'text4.jpg', 'text5.1.jpg', 'text5.2.jpg', 'text5.3.jpg', 'text5.JPG', 'text6.JPG', 'text7.JPG', 'text8.JPG', 'text9.JPG']\n",
      "../cropped text/text1.jpg\n",
      "Image Text:\n",
      "_______________\n",
      "Almost all in\n",
      "Community\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text10.JPG\n",
      "Image Text:\n",
      "_______________\n",
      "Lyeryone\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text11.JPG\n",
      "Image Text:\n",
      "_______________\n",
      "Not in our area to my_knowledgee _\n",
      "Cracked plaster, foundations, dishes, ctce\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text12.JPG\n",
      "Image Text:\n",
      "_______________\n",
      "c. Frightened: . ,\n",
      "No one, few, many, all (in your home) (in_commynity)s ‘general panic Several\n",
      "frightened-No paniceMost thought Gas systen exploded.\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text13.JPG\n",
      "Image Text:\n",
      "_______________\n",
      "Heatof one. or two piotnre windowss, —\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text14.JPG\n",
      "Image Text:\n",
      "_______________\n",
      "Bluford, Jerrson County, Illinois 62814\n",
      "Post Office near North part of community.\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text15.JPG\n",
      "Image Text:\n",
      "_______________\n",
      "Not in our_area to. my_knowledges . ___\n",
      "Cracked plaster, foundations, dishes, etoe\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text16.JPG\n",
      "Image Text:\n",
      "_______________\n",
      "Concrete\n",
      "-Bloek-\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text17.jpg\n",
      "Image Text:\n",
      "_______________\n",
      "Awnings loosened: doorg not_\n",
      "in altionmeant with locks; loud rumbling\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text18.JPG\n",
      "Image Text:\n",
      "_______________\n",
      "Standing\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text19.JPG\n",
      "Image Text:\n",
      "_______________\n",
      "Felt by entire —\n",
      "cémmmity.\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text2.jpg\n",
      "Image Text:\n",
      "_______________\n",
      "small amount shifted\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text20.JPG\n",
      "Image Text:\n",
      "_______________\n",
      ". . i]\n",
      "By r ee SOK oO mt CD t= «1, Fe oi\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text21.JPG\n",
      "Image Text:\n",
      "_______________\n",
      "Moderate\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text22.JPG\n",
      "Image Text:\n",
      "_______________\n",
      ". 1a i,\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text23.JPG\n",
      "Image Text:\n",
      "_______________\n",
      "BUCKNER, FRANKLIN, SLLIHOIS\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text24.JPG\n",
      "Image Text:\n",
      "_______________\n",
      "standing\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text25.JPG\n",
      "Image Text:\n",
      "_______________\n",
      "iL\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text26.JPG\n",
      "Image Text:\n",
      "_______________\n",
      "assume all awake\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text27.JPG\n",
      "Image Text:\n",
      "_______________\n",
      "> More general great surprise than stock\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text28.JPG\n",
      "Image Text:\n",
      "_______________\n",
      "none to knowldge\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text29.JPG\n",
      "Image Text:\n",
      "_______________\n",
      "very slight.\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text3 pre-edit.jpg\n",
      "Image Text:\n",
      "_______________\n",
      "-Rattling of doors & windows.\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text3.jpg\n",
      "Image Text:\n",
      "_______________\n",
      "Rattling of doors & windows\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text30.JPG\n",
      "Image Text:\n",
      "_______________\n",
      "general, no great damage\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text4.jpg\n",
      "Image Text:\n",
      "_______________\n",
      "—Rattling of doors & windows- .\n",
      "none noticed\n",
      "none noticed -\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text5.1.jpg\n",
      "Image Text:\n",
      "_______________\n",
      "Tt felt as if the, building dropped 2 Or 4 ihéhes\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text5.2.jpg\n",
      "Image Text:\n",
      "_______________\n",
      "Teaving.my cnair in Mid arr. ine@en.1in a tew, seconas\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text5.3.jpg\n",
      "Image Text:\n",
      "_______________\n",
      "The OULLGaGINY SAOOK again OUL W1LLELD L@eSS SNOCK.\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text5.JPG\n",
      "Image Text:\n",
      "_______________\n",
      "Daa gla “tf nyc “ous iding dre ect 2 inches —\n",
      "dest Sns A ghahbodPabetotEne wibhe iste ab8hcre ne\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text6.JPG\n",
      "Image Text:\n",
      "_______________\n",
      "Loud rumble,like explosion\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text7.JPG\n",
      "Image Text:\n",
      "_______________\n",
      "NW corne own Square in Town of Ashland, Clay\n",
      "County, /Alaban 36251 a\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text8.JPG\n",
      "Image Text:\n",
      "_______________\n",
      "Quiet, active\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n",
      "../cropped text/text9.JPG\n",
      "Image Text:\n",
      "_______________\n",
      "b. Creaking of building (Describe) Awnings loosened: doorg not_\n",
      "c. Forth noi AtLignment with locks; loud rumbling\n",
      "\f",
      "\n",
      "_______________\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "        \n",
    "directory = '../cropped text/'\n",
    "show = False\n",
    "cv2.destroyAllWindows()\n",
    "print(os.listdir(directory))\n",
    "\n",
    "# Iterate over all image files in the specified directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".JPG\"):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        print(filepath)\n",
    "        \n",
    "        # Read image\n",
    "        img = cv2.imread(filepath)\n",
    "        # Find lines and replace with white (i.e. remove lines)\n",
    "        img = find_and_replace_lines(img, show) \n",
    "        # Blur image\n",
    "        rm_noise_img = remove_noise(img)\n",
    "        # Convert image to grayscale\n",
    "        if len(rm_noise_img.shape) == 3:\n",
    "            gs_img = get_grayscale(rm_noise_img)\n",
    "        else:\n",
    "            gs_img = rm_noise_img\n",
    "        # Apply morph filter to image\n",
    "        m_img = morph(gs_img)\n",
    "        #m_img = cv2.bitwise_not(m_img) # Invert image colors\n",
    "        #m_img = erode(m_img,mode='S')\n",
    "        #m_img = cv2.bitwise_not(m_img) # Invert image colors\n",
    "\n",
    "        # Extract text\n",
    "        print(\"Image Text:\\n_______________\")\n",
    "        custom_config = r'-c tessedit_char_blacklist=éÓóÔôÒòÑñÖö¡ÇçŒœßØøÅåÆæÐð --psm 6'\n",
    "        #custom_config = r'-c tessedit_char_whitelist=\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz ,.;:/1235467890!@#$%^&*\" --psm 6'\n",
    "        print(pytesseract.image_to_string(img,config=custom_config))\n",
    "        print(\"_______________\")\n",
    "        if show:\n",
    "            show_img(m_img,'morph')\n",
    "        print(\"\\n\\n\")\n",
    "    else:\n",
    "        # if not of type .jpg\n",
    "        continue    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "line removal alg:  \n",
    "have original image  \n",
    "detect lines with houghlines  \n",
    "use erosion followed by dialation with a vertical kernel on a copy of the original image  \n",
    "bitwise & with the lines detected by houghlines  \n",
    "subtract the bitwise & mask from the lines detected by houghlines  \n",
    "subtract the masked houghlines from the original image - lines are now removed  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
